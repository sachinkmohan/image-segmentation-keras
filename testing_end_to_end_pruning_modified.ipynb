{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2bd9a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_segmentation.models.unet import vgg_unet\n",
    "\n",
    "model = vgg_unet(n_classes=50 ,  input_height=320, input_width=640  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b7a6960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from keras_segmentation.models.unet import vgg_unet\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = vgg_unet(n_classes=50 ,  input_height=320, input_width=640  )\n",
    "model5=load_model('./dg_base_ep1.h5')\n",
    "print('done')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30fe374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model6=model5.load_weights('divam_ss_base.03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "639d9fa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'summary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9b9424b80928>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel6\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'summary'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cce29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model.load_weights('divam_ss_base.03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b578bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_segmentation.models.all_models import model_from_name\n",
    "import six\n",
    "from keras_segmentation.data_utils.data_loader import image_segmentation_generator, \\\n",
    "    verify_segmentation_dataset\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b00353",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model, six.string_types):\n",
    "    # create the model from the name\n",
    "    assert (n_classes is not None), \"Please provide the n_classes\"\n",
    "    if (input_height is not None) and (input_width is not None):\n",
    "        model = model_from_name[model](\n",
    "            n_classes, input_height=input_height, input_width=input_width)\n",
    "    else:\n",
    "        model = model_from_name[model](n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3a7b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = model.load_weights('divam_ss_base.03.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b20bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = model.n_classes\n",
    "input_height = model.input_height\n",
    "input_width = model.input_width\n",
    "output_height = model.output_height\n",
    "output_width = model.output_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a2cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 50\n",
    "input_height = 320\n",
    "input_width = 640\n",
    "output_height = 160\n",
    "output_width = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "effe6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_k = 'categorical_crossentropy'\n",
    "model.compile(loss=loss_k,\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5cd6d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=\"dataset1/images_prepped_train/\"\n",
    "train_annotations=\"dataset1/annotations_prepped_train/\"\n",
    "#input_height=None\n",
    "#input_width=None\n",
    "#n_classes=None\n",
    "verify_dataset=True\n",
    "checkpoints_path=None\n",
    "epochs=1\n",
    "batch_size=2\n",
    "validate=False\n",
    "val_images=None\n",
    "val_annotations=None\n",
    "val_batch_size=2\n",
    "auto_resume_checkpoint=False\n",
    "load_weights=None\n",
    "steps_per_epoch=512\n",
    "val_steps_per_epoch=512\n",
    "gen_use_multiprocessing=False\n",
    "ignore_zero_class=False\n",
    "optimizer_name='adam'\n",
    "do_augment=False\n",
    "augmentation_name=\"aug_all\",\n",
    "callbacks=None\n",
    "custom_augmentation=None\n",
    "other_inputs_paths=None\n",
    "preprocessing=None\n",
    "read_image_type=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "196fca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = image_segmentation_generator(\n",
    "        train_images, train_annotations,  batch_size,  n_classes,\n",
    "        input_height, input_width, output_height, output_width,\n",
    "        do_augment=do_augment, augmentation_name=augmentation_name,\n",
    "        custom_augmentation=custom_augmentation, other_inputs_paths=other_inputs_paths,\n",
    "        preprocessing=preprocessing, read_image_type=read_image_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18e45c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints_path = 'divam_ss_base_test'\n",
    "default_callback = ModelCheckpoint(\n",
    "            filepath=checkpoints_path + \".{epoch:02d}.h5\",\n",
    "            save_weights_only=False,\n",
    "            verbose=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "250735f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 74s 114ms/step - loss: 0.8632 - accuracy: 0.7499\n",
      "\n",
      "Epoch 00001: saving model to divam_ss_base_test.01.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fda1ebc2c50>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_epoch=0\n",
    "model.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                  epochs=epochs, callbacks=default_callback, initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dg_base_ep1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d0a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3=model.load_weights('dg_base_ep1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model2.predict_segmentation(\n",
    "    inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
    "    out_fname=\"/tmp/out.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61e590d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "inp = cv2.imread(\"dataset1/images_prepped_test/0016E5_07965.png\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064bab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=model.load_model('dg_base_ep1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af352c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec952cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_array(image_input,\n",
    "                    width, height,\n",
    "                    imgNorm=\"sub_mean\", ordering='channels_first', read_image_type=1):\n",
    "    \"\"\" Load image array from input \"\"\"\n",
    "\n",
    "    if type(image_input) is np.ndarray:\n",
    "        # It is already an array, use it as it is\n",
    "        img = image_input\n",
    "    elif isinstance(image_input, six.string_types):\n",
    "        if not os.path.isfile(image_input):\n",
    "            raise DataLoaderError(\"get_image_array: path {0} doesn't exist\"\n",
    "                                  .format(image_input))\n",
    "        img = cv2.imread(image_input, read_image_type)\n",
    "    else:\n",
    "        raise DataLoaderError(\"get_image_array: Can't process input type {0}\"\n",
    "                              .format(str(type(image_input))))\n",
    "\n",
    "    if imgNorm == \"sub_and_divide\":\n",
    "        img = np.float32(cv2.resize(img, (width, height))) / 127.5 - 1\n",
    "    elif imgNorm == \"sub_mean\":\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img = np.atleast_3d(img)\n",
    "\n",
    "        means = [103.939, 116.779, 123.68]\n",
    "\n",
    "        for i in range(min(img.shape[2], len(means))):\n",
    "            img[:, :, i] -= means[i]\n",
    "\n",
    "        img = img[:, :, ::-1]\n",
    "    elif imgNorm == \"divide\":\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img = img/255.0\n",
    "\n",
    "    if ordering == 'channels_first':\n",
    "        img = np.rollaxis(img, 2, 0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8de160ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "IMAGE_ORDERING = \"channels_last\"\n",
    "x = get_image_array(inp, input_width, input_height,\n",
    "                    ordering=IMAGE_ORDERING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1596b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = model.predict(np.array([x]))[0]\n",
    "pr = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c51e8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class_colors = [(random.randint(0, 255), random.randint(\n",
    "    0, 255), random.randint(0, 255)) for _ in range(5000)]\n",
    "\n",
    "def visualize_segmentation(seg_arr, inp_img=None, n_classes=None,\n",
    "                           colors=class_colors, class_names=None,\n",
    "                           overlay_img=False, show_legends=False,\n",
    "                           prediction_width=None, prediction_height=None):\n",
    "\n",
    "    if n_classes is None:\n",
    "        n_classes = np.max(seg_arr)\n",
    "\n",
    "    seg_img = get_colored_segmentation_image(seg_arr, n_classes, colors=colors)\n",
    "\n",
    "    if inp_img is not None:\n",
    "        original_h = inp_img.shape[0]\n",
    "        original_w = inp_img.shape[1]\n",
    "        seg_img = cv2.resize(seg_img, (original_w, original_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    if (prediction_height is not None) and (prediction_width is not None):\n",
    "        seg_img = cv2.resize(seg_img, (prediction_width, prediction_height), interpolation=cv2.INTER_NEAREST)\n",
    "        if inp_img is not None:\n",
    "            inp_img = cv2.resize(inp_img,\n",
    "                                 (prediction_width, prediction_height))\n",
    "\n",
    "    if overlay_img:\n",
    "        assert inp_img is not None\n",
    "        seg_img = overlay_seg_image(inp_img, seg_img)\n",
    "\n",
    "    if show_legends:\n",
    "        assert class_names is not None\n",
    "        legend_img = get_legends(class_names, colors=colors)\n",
    "\n",
    "        seg_img = concat_lenends(seg_img, legend_img)\n",
    "\n",
    "    return seg_img\n",
    "\n",
    "def get_colored_segmentation_image(seg_arr, n_classes, colors=class_colors):\n",
    "    output_height = seg_arr.shape[0]\n",
    "    output_width = seg_arr.shape[1]\n",
    "\n",
    "    seg_img = np.zeros((output_height, output_width, 3))\n",
    "\n",
    "    for c in range(n_classes):\n",
    "        seg_arr_c = seg_arr[:, :] == c\n",
    "        seg_img[:, :, 0] += ((seg_arr_c)*(colors[c][0])).astype('uint8')\n",
    "        seg_img[:, :, 1] += ((seg_arr_c)*(colors[c][1])).astype('uint8')\n",
    "        seg_img[:, :, 2] += ((seg_arr_c)*(colors[c][2])).astype('uint8')\n",
    "\n",
    "    return seg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01f30607",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_img=False\n",
    "show_legends=False\n",
    "class_names=None\n",
    "prediction_width=None\n",
    "prediction_height=None\n",
    "\n",
    "seg_img = visualize_segmentation(pr, inp, n_classes=n_classes,\n",
    "                                 colors=class_colors, overlay_img=overlay_img,\n",
    "                                 show_legends=show_legends,\n",
    "                                 class_names=class_names,\n",
    "                                 prediction_width=prediction_width,\n",
    "                                 prediction_height=prediction_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a3a3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    cv2.imshow('im', seg_img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60084169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a89b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot \n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule as pruning_sched\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ce848",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=1000)\n",
    "}\n",
    "\n",
    "#'''\n",
    "\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_filepath = 'pruned.{epoch:02d}.h5'\n",
    "\n",
    "p_checkpoint = ModelCheckpoint(p_filepath,save_best_only=True,save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e73831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './pruning_logs'\n",
    "p_callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    # Log sparsity and other metrics in Tensorboard.\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir),p_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133d2697",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_pruning.compile(loss=loss_k,\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch=0\n",
    "model_for_pruning.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                  epochs=1, callbacks=p_callbacks, initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e6f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model_for_pruning.predict_segmentation(\n",
    "    inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
    "    out_fname=\"/tmp/out.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb63b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86303cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    train_images =  \"dataset1/images_prepped_train/\",\n",
    "    train_annotations = \"dataset1/annotations_prepped_train/\",\n",
    "    checkpoints_path = \"/tmp/vgg_unet_1\" , epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5591fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict_segmentation(\n",
    "    inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
    "    out_fname=\"/tmp/out.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e87a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b1e175",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.evaluate_segmentation( inp_images_dir=\"dataset1/images_prepped_test/\"  , annotations_dir=\"dataset1/annotations_prepped_test/\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81afd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './pruning_logs'\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    # Log sparsity and other metrics in Tensorboard.\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f85bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_pruning.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3181b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

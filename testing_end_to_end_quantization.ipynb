{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b578bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_segmentation.models.all_models import model_from_name\n",
    "import six\n",
    "from keras_segmentation.data_utils.data_loader import image_segmentation_generator, \\\n",
    "    verify_segmentation_dataset\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "## loading tensorboard\n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d28933",
   "metadata": {},
   "source": [
    "### End to end training of the sample model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bd9a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_segmentation.models.unet import vgg_unet\n",
    "\n",
    "model = vgg_unet(n_classes=50 ,  input_height=320, input_width=640  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9ab10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(\n",
    "    train_images =  \"dataset1/images_prepped_train/\",\n",
    "    train_annotations = \"dataset1/annotations_prepped_train/\",\n",
    "    checkpoints_path = \"/tmp/vgg_unet_1\" , epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad4491c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model1.predict_segmentation(\n",
    "    inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
    "    out_fname=\"/tmp/out.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb84f6e",
   "metadata": {},
   "source": [
    "### Loading a simple model with weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c288f",
   "metadata": {},
   "source": [
    "#### vgg_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1397a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_segmentation.models.unet import vgg_unet\n",
    "\n",
    "model_base = vgg_unet(n_classes=50 ,  input_height=320, input_width=640  )\n",
    "#model_base.load_weights('divam_ss_base_weights_ep20.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5968cd9",
   "metadata": {},
   "source": [
    "#### resnet50_segnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c992af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_segmentation.models.segnet import resnet50_segnet\n",
    "\n",
    "model_base = resnet50_segnet(n_classes=50 ,  input_height=320, input_width=640)\n",
    "model_base.load_weights('divam_ss_base_weights_r_segnet.19.h5')\n",
    "#model_pruned.load_weights('divam_ss_pruned_weights_r_segnet19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4772a089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e24258e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohan/virtualenv/divamgupta_tf2/lib/python3.6/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot \n",
    "\n",
    "quant_aware_model = tfmot.quantization.keras.quantize_model(model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313bfc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 320, 640, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "quantize_layer (QuantizeLayer)  (None, 320, 640, 3)  3           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "quant_zero_padding2d (QuantizeW (None, 326, 646, 3)  1           quantize_layer[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv1 (QuantizeWrapperV2) (None, 160, 320, 64) 9601        quant_zero_padding2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn_conv1 (QuantizeWrapper (None, 160, 320, 64) 257         quant_conv1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation (QuantizeWrapp (None, 160, 320, 64) 3           quant_bn_conv1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "quant_max_pooling2d (QuantizeWr (None, 79, 159, 64)  1           quant_activation[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "quant_res2a_branch2a (QuantizeW (None, 79, 159, 64)  4289        quant_max_pooling2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn2a_branch2a (QuantizeWr (None, 79, 159, 64)  257         quant_res2a_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_1 (QuantizeWra (None, 79, 159, 64)  3           quant_bn2a_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res2a_branch2b (QuantizeW (None, 79, 159, 64)  37057       quant_activation_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn2a_branch2b (QuantizeWr (None, 79, 159, 64)  257         quant_res2a_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_2 (QuantizeWra (None, 79, 159, 64)  3           quant_bn2a_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res2a_branch2c (QuantizeW (None, 79, 159, 256) 17153       quant_activation_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_res2a_branch1 (QuantizeWr (None, 79, 159, 256) 17153       quant_max_pooling2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn2a_branch2c (QuantizeWr (None, 79, 159, 256) 1027        quant_res2a_branch2c[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn2a_branch1 (QuantizeWra (None, 79, 159, 256) 1027        quant_res2a_branch1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_add (QuantizeWrapperV2)   (None, 79, 159, 256) 1           quant_bn2a_branch2c[0][0]        \n",
      "                                                                 quant_bn2a_branch1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_3 (QuantizeWra (None, 79, 159, 256) 3           quant_add[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "quant_res2b_branch2a (QuantizeW (None, 79, 159, 64)  16577       quant_activation_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn2b_branch2a (QuantizeWr (None, 79, 159, 64)  257         quant_res2b_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_4 (QuantizeWra (None, 79, 159, 64)  3           quant_bn2b_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res2b_branch2b (QuantizeW (None, 79, 159, 64)  37057       quant_activation_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn2b_branch2b (QuantizeWr (None, 79, 159, 64)  257         quant_res2b_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_5 (QuantizeWra (None, 79, 159, 64)  3           quant_bn2b_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res2b_branch2c (QuantizeW (None, 79, 159, 256) 17153       quant_activation_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn2b_branch2c (QuantizeWr (None, 79, 159, 256) 1027        quant_res2b_branch2c[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_1 (QuantizeWrapperV2) (None, 79, 159, 256) 1           quant_bn2b_branch2c[0][0]        \n",
      "                                                                 quant_activation_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_6 (QuantizeWra (None, 79, 159, 256) 3           quant_add_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "quant_res2c_branch2a (QuantizeW (None, 79, 159, 64)  16577       quant_activation_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn2c_branch2a (QuantizeWr (None, 79, 159, 64)  257         quant_res2c_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_7 (QuantizeWra (None, 79, 159, 64)  3           quant_bn2c_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res2c_branch2b (QuantizeW (None, 79, 159, 64)  37057       quant_activation_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn2c_branch2b (QuantizeWr (None, 79, 159, 64)  257         quant_res2c_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_8 (QuantizeWra (None, 79, 159, 64)  3           quant_bn2c_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res2c_branch2c (QuantizeW (None, 79, 159, 256) 17153       quant_activation_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn2c_branch2c (QuantizeWr (None, 79, 159, 256) 1027        quant_res2c_branch2c[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_2 (QuantizeWrapperV2) (None, 79, 159, 256) 1           quant_bn2c_branch2c[0][0]        \n",
      "                                                                 quant_activation_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_9 (QuantizeWra (None, 79, 159, 256) 3           quant_add_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "quant_res3a_branch2a (QuantizeW (None, 40, 80, 128)  33153       quant_activation_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn3a_branch2a (QuantizeWr (None, 40, 80, 128)  513         quant_res3a_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_10 (QuantizeWr (None, 40, 80, 128)  3           quant_bn3a_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res3a_branch2b (QuantizeW (None, 40, 80, 128)  147841      quant_activation_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn3a_branch2b (QuantizeWr (None, 40, 80, 128)  513         quant_res3a_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_11 (QuantizeWr (None, 40, 80, 128)  3           quant_bn3a_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res3a_branch2c (QuantizeW (None, 40, 80, 512)  67073       quant_activation_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res3a_branch1 (QuantizeWr (None, 40, 80, 512)  132609      quant_activation_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn3a_branch2c (QuantizeWr (None, 40, 80, 512)  2051        quant_res3a_branch2c[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn3a_branch1 (QuantizeWra (None, 40, 80, 512)  2051        quant_res3a_branch1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_3 (QuantizeWrapperV2) (None, 40, 80, 512)  1           quant_bn3a_branch2c[0][0]        \n",
      "                                                                 quant_bn3a_branch1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_12 (QuantizeWr (None, 40, 80, 512)  3           quant_add_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "quant_res3b_branch2a (QuantizeW (None, 40, 80, 128)  65921       quant_activation_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn3b_branch2a (QuantizeWr (None, 40, 80, 128)  513         quant_res3b_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_13 (QuantizeWr (None, 40, 80, 128)  3           quant_bn3b_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res3b_branch2b (QuantizeW (None, 40, 80, 128)  147841      quant_activation_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn3b_branch2b (QuantizeWr (None, 40, 80, 128)  513         quant_res3b_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_14 (QuantizeWr (None, 40, 80, 128)  3           quant_bn3b_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res3b_branch2c (QuantizeW (None, 40, 80, 512)  67073       quant_activation_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn3b_branch2c (QuantizeWr (None, 40, 80, 512)  2051        quant_res3b_branch2c[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_4 (QuantizeWrapperV2) (None, 40, 80, 512)  1           quant_bn3b_branch2c[0][0]        \n",
      "                                                                 quant_activation_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_15 (QuantizeWr (None, 40, 80, 512)  3           quant_add_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "quant_res3c_branch2a (QuantizeW (None, 40, 80, 128)  65921       quant_activation_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn3c_branch2a (QuantizeWr (None, 40, 80, 128)  513         quant_res3c_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_16 (QuantizeWr (None, 40, 80, 128)  3           quant_bn3c_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res3c_branch2b (QuantizeW (None, 40, 80, 128)  147841      quant_activation_16[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn3c_branch2b (QuantizeWr (None, 40, 80, 128)  513         quant_res3c_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_17 (QuantizeWr (None, 40, 80, 128)  3           quant_bn3c_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res3c_branch2c (QuantizeW (None, 40, 80, 512)  67073       quant_activation_17[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn3c_branch2c (QuantizeWr (None, 40, 80, 512)  2051        quant_res3c_branch2c[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_5 (QuantizeWrapperV2) (None, 40, 80, 512)  1           quant_bn3c_branch2c[0][0]        \n",
      "                                                                 quant_activation_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_18 (QuantizeWr (None, 40, 80, 512)  3           quant_add_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "quant_res3d_branch2a (QuantizeW (None, 40, 80, 128)  65921       quant_activation_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn3d_branch2a (QuantizeWr (None, 40, 80, 128)  513         quant_res3d_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_19 (QuantizeWr (None, 40, 80, 128)  3           quant_bn3d_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res3d_branch2b (QuantizeW (None, 40, 80, 128)  147841      quant_activation_19[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn3d_branch2b (QuantizeWr (None, 40, 80, 128)  513         quant_res3d_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_20 (QuantizeWr (None, 40, 80, 128)  3           quant_bn3d_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res3d_branch2c (QuantizeW (None, 40, 80, 512)  67073       quant_activation_20[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn3d_branch2c (QuantizeWr (None, 40, 80, 512)  2051        quant_res3d_branch2c[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_6 (QuantizeWrapperV2) (None, 40, 80, 512)  1           quant_bn3d_branch2c[0][0]        \n",
      "                                                                 quant_activation_18[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_21 (QuantizeWr (None, 40, 80, 512)  3           quant_add_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4a_branch2a (QuantizeW (None, 20, 40, 256)  131841      quant_activation_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4a_branch2a (QuantizeWr (None, 20, 40, 256)  1025        quant_res4a_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_22 (QuantizeWr (None, 20, 40, 256)  3           quant_bn4a_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4a_branch2b (QuantizeW (None, 20, 40, 256)  590593      quant_activation_22[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4a_branch2b (QuantizeWr (None, 20, 40, 256)  1025        quant_res4a_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_23 (QuantizeWr (None, 20, 40, 256)  3           quant_bn4a_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4a_branch2c (QuantizeW (None, 20, 40, 1024) 265217      quant_activation_23[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4a_branch1 (QuantizeWr (None, 20, 40, 1024) 527361      quant_activation_21[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4a_branch2c (QuantizeWr (None, 20, 40, 1024) 4099        quant_res4a_branch2c[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4a_branch1 (QuantizeWra (None, 20, 40, 1024) 4099        quant_res4a_branch1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_7 (QuantizeWrapperV2) (None, 20, 40, 1024) 1           quant_bn4a_branch2c[0][0]        \n",
      "                                                                 quant_bn4a_branch1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_24 (QuantizeWr (None, 20, 40, 1024) 3           quant_add_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4b_branch2a (QuantizeW (None, 20, 40, 256)  262913      quant_activation_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4b_branch2a (QuantizeWr (None, 20, 40, 256)  1025        quant_res4b_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_25 (QuantizeWr (None, 20, 40, 256)  3           quant_bn4b_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4b_branch2b (QuantizeW (None, 20, 40, 256)  590593      quant_activation_25[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4b_branch2b (QuantizeWr (None, 20, 40, 256)  1025        quant_res4b_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_26 (QuantizeWr (None, 20, 40, 256)  3           quant_bn4b_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4b_branch2c (QuantizeW (None, 20, 40, 1024) 265217      quant_activation_26[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4b_branch2c (QuantizeWr (None, 20, 40, 1024) 4099        quant_res4b_branch2c[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_8 (QuantizeWrapperV2) (None, 20, 40, 1024) 1           quant_bn4b_branch2c[0][0]        \n",
      "                                                                 quant_activation_24[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_27 (QuantizeWr (None, 20, 40, 1024) 3           quant_add_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4c_branch2a (QuantizeW (None, 20, 40, 256)  262913      quant_activation_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4c_branch2a (QuantizeWr (None, 20, 40, 256)  1025        quant_res4c_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_28 (QuantizeWr (None, 20, 40, 256)  3           quant_bn4c_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4c_branch2b (QuantizeW (None, 20, 40, 256)  590593      quant_activation_28[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4c_branch2b (QuantizeWr (None, 20, 40, 256)  1025        quant_res4c_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_29 (QuantizeWr (None, 20, 40, 256)  3           quant_bn4c_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4c_branch2c (QuantizeW (None, 20, 40, 1024) 265217      quant_activation_29[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4c_branch2c (QuantizeWr (None, 20, 40, 1024) 4099        quant_res4c_branch2c[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_9 (QuantizeWrapperV2) (None, 20, 40, 1024) 1           quant_bn4c_branch2c[0][0]        \n",
      "                                                                 quant_activation_27[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_30 (QuantizeWr (None, 20, 40, 1024) 3           quant_add_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4d_branch2a (QuantizeW (None, 20, 40, 256)  262913      quant_activation_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4d_branch2a (QuantizeWr (None, 20, 40, 256)  1025        quant_res4d_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_31 (QuantizeWr (None, 20, 40, 256)  3           quant_bn4d_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4d_branch2b (QuantizeW (None, 20, 40, 256)  590593      quant_activation_31[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4d_branch2b (QuantizeWr (None, 20, 40, 256)  1025        quant_res4d_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_32 (QuantizeWr (None, 20, 40, 256)  3           quant_bn4d_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4d_branch2c (QuantizeW (None, 20, 40, 1024) 265217      quant_activation_32[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4d_branch2c (QuantizeWr (None, 20, 40, 1024) 4099        quant_res4d_branch2c[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_10 (QuantizeWrapperV2 (None, 20, 40, 1024) 1           quant_bn4d_branch2c[0][0]        \n",
      "                                                                 quant_activation_30[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_33 (QuantizeWr (None, 20, 40, 1024) 3           quant_add_10[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4e_branch2a (QuantizeW (None, 20, 40, 256)  262913      quant_activation_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4e_branch2a (QuantizeWr (None, 20, 40, 256)  1025        quant_res4e_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_34 (QuantizeWr (None, 20, 40, 256)  3           quant_bn4e_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4e_branch2b (QuantizeW (None, 20, 40, 256)  590593      quant_activation_34[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4e_branch2b (QuantizeWr (None, 20, 40, 256)  1025        quant_res4e_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_35 (QuantizeWr (None, 20, 40, 256)  3           quant_bn4e_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4e_branch2c (QuantizeW (None, 20, 40, 1024) 265217      quant_activation_35[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4e_branch2c (QuantizeWr (None, 20, 40, 1024) 4099        quant_res4e_branch2c[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_11 (QuantizeWrapperV2 (None, 20, 40, 1024) 1           quant_bn4e_branch2c[0][0]        \n",
      "                                                                 quant_activation_33[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_36 (QuantizeWr (None, 20, 40, 1024) 3           quant_add_11[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4f_branch2a (QuantizeW (None, 20, 40, 256)  262913      quant_activation_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4f_branch2a (QuantizeWr (None, 20, 40, 256)  1025        quant_res4f_branch2a[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_37 (QuantizeWr (None, 20, 40, 256)  3           quant_bn4f_branch2a[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4f_branch2b (QuantizeW (None, 20, 40, 256)  590593      quant_activation_37[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4f_branch2b (QuantizeWr (None, 20, 40, 256)  1025        quant_res4f_branch2b[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_38 (QuantizeWr (None, 20, 40, 256)  3           quant_bn4f_branch2b[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_res4f_branch2c (QuantizeW (None, 20, 40, 1024) 265217      quant_activation_38[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_bn4f_branch2c (QuantizeWr (None, 20, 40, 1024) 4099        quant_res4f_branch2c[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "quant_add_12 (QuantizeWrapperV2 (None, 20, 40, 1024) 1           quant_bn4f_branch2c[0][0]        \n",
      "                                                                 quant_activation_36[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_39 (QuantizeWr (None, 20, 40, 1024) 3           quant_add_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "quant_zero_padding2d_2 (Quantiz (None, 22, 42, 1024) 1           quant_activation_39[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv2d (QuantizeWrapperV2 (None, 20, 40, 512)  4720129     quant_zero_padding2d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "quant_batch_normalization (Quan (None, 20, 40, 512)  2051        quant_conv2d[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "quant_up_sampling2d (QuantizeWr (None, 40, 80, 512)  3           quant_batch_normalization[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "quant_zero_padding2d_3 (Quantiz (None, 42, 82, 512)  1           quant_up_sampling2d[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv2d_1 (QuantizeWrapper (None, 40, 80, 256)  1180417     quant_zero_padding2d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "quant_batch_normalization_1 (Qu (None, 40, 80, 256)  1027        quant_conv2d_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "quant_up_sampling2d_1 (Quantize (None, 80, 160, 256) 3           quant_batch_normalization_1[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "quant_zero_padding2d_4 (Quantiz (None, 82, 162, 256) 1           quant_up_sampling2d_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv2d_2 (QuantizeWrapper (None, 80, 160, 128) 295297      quant_zero_padding2d_4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "quant_batch_normalization_2 (Qu (None, 80, 160, 128) 515         quant_conv2d_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "quant_up_sampling2d_2 (Quantize (None, 160, 320, 128 3           quant_batch_normalization_2[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "quant_zero_padding2d_5 (Quantiz (None, 162, 322, 128 1           quant_up_sampling2d_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "quant_seg_feats (QuantizeWrappe (None, 160, 320, 64) 73921       quant_zero_padding2d_5[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "quant_batch_normalization_3 (Qu (None, 160, 320, 64) 259         quant_seg_feats[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "quant_conv2d_3 (QuantizeWrapper (None, 160, 320, 50) 28953       quant_batch_normalization_3[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "quant_reshape (QuantizeWrapperV (None, 51200, 50)    1           quant_conv2d_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "quant_activation_49 (QuantizeWr (None, 51200, 50)    1           quant_reshape[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 14,922,616\n",
      "Trainable params: 14,857,202\n",
      "Non-trainable params: 65,414\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "quant_aware_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25951a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc13aa02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b20bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = model_base.n_classes\n",
    "input_height = model_base.input_height\n",
    "input_width = model_base.input_width\n",
    "output_height = model_base.output_height\n",
    "output_width = model_base.output_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a2cbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 50\n",
    "input_height = 320\n",
    "input_width = 640\n",
    "output_height = 160\n",
    "output_width = 320"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da4a32f",
   "metadata": {},
   "source": [
    "### Execute this if you are planning to predict or train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5cd6d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images=\"dataset1/images_prepped_train/\"\n",
    "train_annotations=\"dataset1/annotations_prepped_train/\"\n",
    "#input_height=None\n",
    "#input_width=None\n",
    "#n_classes=None\n",
    "verify_dataset=True\n",
    "checkpoints_path=None\n",
    "epochs=20\n",
    "batch_size=2\n",
    "validate=False\n",
    "val_images=None\n",
    "val_annotations=None\n",
    "val_batch_size=2\n",
    "auto_resume_checkpoint=False\n",
    "load_weights=None\n",
    "steps_per_epoch=512\n",
    "val_steps_per_epoch=512\n",
    "gen_use_multiprocessing=False\n",
    "ignore_zero_class=False\n",
    "optimizer_name='adam'\n",
    "do_augment=False\n",
    "augmentation_name=\"aug_all\",\n",
    "callbacks=None\n",
    "custom_augmentation=None\n",
    "other_inputs_paths=None\n",
    "preprocessing=None\n",
    "read_image_type=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "196fca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = image_segmentation_generator(\n",
    "        train_images, train_annotations,  batch_size,  n_classes,\n",
    "        input_height, input_width, output_height, output_width,\n",
    "        do_augment=do_augment, augmentation_name=augmentation_name,\n",
    "        custom_augmentation=custom_augmentation, other_inputs_paths=other_inputs_paths,\n",
    "        preprocessing=preprocessing, read_image_type=read_image_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18e45c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow \n",
    "\n",
    "checkpoints_path = 'divam_ss_q_model_'\n",
    "default_callback = ModelCheckpoint(\n",
    "            filepath=checkpoints_path + \".{epoch:02d}.h5\",\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            verbose=True,\n",
    "            monitor='loss'\n",
    "        )\n",
    "tbCallBack = tensorflow.keras.callbacks.TensorBoard(log_dir='./Graph', histogram_freq=0, write_graph=True, write_images=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "effe6d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_k = 'categorical_crossentropy'\n",
    "quant_aware_model.compile(loss=loss_k,\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d4d783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "logs_base_dir = \"./Graph\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "#%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "250735f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "512/512 [==============================] - 161s 298ms/step - loss: 0.1196 - accuracy: 0.9606\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.11965, saving model to divam_ss_q_model_.01.h5\n",
      "Epoch 2/20\n",
      "512/512 [==============================] - 146s 285ms/step - loss: 0.0800 - accuracy: 0.9695\n",
      "\n",
      "Epoch 00002: loss improved from 0.11965 to 0.08000, saving model to divam_ss_q_model_.02.h5\n",
      "Epoch 3/20\n",
      "512/512 [==============================] - 147s 286ms/step - loss: 0.0863 - accuracy: 0.9673\n",
      "\n",
      "Epoch 00003: loss did not improve from 0.08000\n",
      "Epoch 4/20\n",
      "512/512 [==============================] - 147s 286ms/step - loss: 0.0875 - accuracy: 0.9669\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.08000\n",
      "Epoch 5/20\n",
      "512/512 [==============================] - 147s 286ms/step - loss: 0.0852 - accuracy: 0.9676\n",
      "\n",
      "Epoch 00005: loss did not improve from 0.08000\n",
      "Epoch 6/20\n",
      "512/512 [==============================] - 147s 287ms/step - loss: 0.0836 - accuracy: 0.9681\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.08000\n",
      "Epoch 7/20\n",
      "512/512 [==============================] - 147s 287ms/step - loss: 0.0838 - accuracy: 0.9680\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.08000\n",
      "Epoch 8/20\n",
      "512/512 [==============================] - 147s 286ms/step - loss: 0.0839 - accuracy: 0.9678\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.08000\n",
      "Epoch 9/20\n",
      "512/512 [==============================] - 147s 287ms/step - loss: 0.0806 - accuracy: 0.9689\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.08000\n",
      "Epoch 10/20\n",
      "512/512 [==============================] - 147s 286ms/step - loss: 0.0779 - accuracy: 0.9699\n",
      "\n",
      "Epoch 00010: loss improved from 0.08000 to 0.07788, saving model to divam_ss_q_model_.10.h5\n",
      "Epoch 11/20\n",
      "512/512 [==============================] - 147s 287ms/step - loss: 0.0794 - accuracy: 0.9692\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.07788\n",
      "Epoch 12/20\n",
      "512/512 [==============================] - 147s 287ms/step - loss: 0.0794 - accuracy: 0.9693\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.07788\n",
      "Epoch 13/20\n",
      "512/512 [==============================] - 147s 286ms/step - loss: 0.0786 - accuracy: 0.9697\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.07788\n",
      "Epoch 14/20\n",
      "512/512 [==============================] - 147s 287ms/step - loss: 0.0762 - accuracy: 0.9703\n",
      "\n",
      "Epoch 00014: loss improved from 0.07788 to 0.07623, saving model to divam_ss_q_model_.14.h5\n",
      "Epoch 15/20\n",
      "512/512 [==============================] - 147s 286ms/step - loss: 0.0746 - accuracy: 0.9709\n",
      "\n",
      "Epoch 00015: loss improved from 0.07623 to 0.07462, saving model to divam_ss_q_model_.15.h5\n",
      "Epoch 16/20\n",
      "512/512 [==============================] - 147s 287ms/step - loss: 0.1722 - accuracy: 0.9409\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.07462\n",
      "Epoch 17/20\n",
      "512/512 [==============================] - 147s 287ms/step - loss: 0.1412 - accuracy: 0.9498\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.07462\n",
      "Epoch 18/20\n",
      "512/512 [==============================] - 147s 286ms/step - loss: 0.0757 - accuracy: 0.9701\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.07462\n",
      "Epoch 19/20\n",
      "512/512 [==============================] - 147s 287ms/step - loss: 0.0654 - accuracy: 0.9739\n",
      "\n",
      "Epoch 00019: loss improved from 0.07462 to 0.06539, saving model to divam_ss_q_model_.19.h5\n",
      "Epoch 20/20\n",
      "512/512 [==============================] - 147s 287ms/step - loss: 0.0674 - accuracy: 0.9733\n",
      "\n",
      "Epoch 00020: loss did not improve from 0.06539\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdcfc108668>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_epoch=0\n",
    "quant_aware_model.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                  epochs=epochs, callbacks=[default_callback,tbCallBack], initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f66232",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('divam_ss_base_weights_ep20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6f5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir path_to_c/Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2809d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model_for_pruning.predict_segmentation(\n",
    "    inp=\"dataset1/images_prepped_test/0016E5_07965.png\",\n",
    "    out_fname=\"/tmp/out.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3321ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dg_base_ep20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfef2b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064bab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=model.load_model('dg_base_ep1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af352c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec952cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_array(image_input,\n",
    "                    width, height,\n",
    "                    imgNorm=\"sub_mean\", ordering='channels_first', read_image_type=1):\n",
    "    \"\"\" Load image array from input \"\"\"\n",
    "\n",
    "    if type(image_input) is np.ndarray:\n",
    "        # It is already an array, use it as it is\n",
    "        img = image_input\n",
    "    elif isinstance(image_input, six.string_types):\n",
    "        if not os.path.isfile(image_input):\n",
    "            raise DataLoaderError(\"get_image_array: path {0} doesn't exist\"\n",
    "                                  .format(image_input))\n",
    "        img = cv2.imread(image_input, read_image_type)\n",
    "    else:\n",
    "        raise DataLoaderError(\"get_image_array: Can't process input type {0}\"\n",
    "                              .format(str(type(image_input))))\n",
    "\n",
    "    if imgNorm == \"sub_and_divide\":\n",
    "        img = np.float32(cv2.resize(img, (width, height))) / 127.5 - 1\n",
    "    elif imgNorm == \"sub_mean\":\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img = np.atleast_3d(img)\n",
    "\n",
    "        means = [103.939, 116.779, 123.68]\n",
    "\n",
    "        for i in range(min(img.shape[2], len(means))):\n",
    "            img[:, :, i] -= means[i]\n",
    "\n",
    "        img = img[:, :, ::-1]\n",
    "    elif imgNorm == \"divide\":\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img = img/255.0\n",
    "\n",
    "    if ordering == 'channels_first':\n",
    "        img = np.rollaxis(img, 2, 0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8de160ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "IMAGE_ORDERING = \"channels_last\"\n",
    "x = get_image_array(inp, input_width, input_height,\n",
    "                    ordering=IMAGE_ORDERING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1596b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = quant_aware_model.predict(np.array([x]))[0]\n",
    "pr_q = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616a597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e8053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class_colors = [(random.randint(0, 255), random.randint(\n",
    "    0, 255), random.randint(0, 255)) for _ in range(5000)]\n",
    "\n",
    "def visualize_segmentation(seg_arr, inp_img=None, n_classes=None,\n",
    "                           colors=class_colors, class_names=None,\n",
    "                           overlay_img=False, show_legends=False,\n",
    "                           prediction_width=None, prediction_height=None):\n",
    "\n",
    "    if n_classes is None:\n",
    "        n_classes = np.max(seg_arr)\n",
    "\n",
    "    seg_img = get_colored_segmentation_image(seg_arr, n_classes, colors=colors)\n",
    "\n",
    "    if inp_img is not None:\n",
    "        original_h = inp_img.shape[0]\n",
    "        original_w = inp_img.shape[1]\n",
    "        seg_img = cv2.resize(seg_img, (original_w, original_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    if (prediction_height is not None) and (prediction_width is not None):\n",
    "        seg_img = cv2.resize(seg_img, (prediction_width, prediction_height), interpolation=cv2.INTER_NEAREST)\n",
    "        if inp_img is not None:\n",
    "            inp_img = cv2.resize(inp_img,\n",
    "                                 (prediction_width, prediction_height))\n",
    "\n",
    "    if overlay_img:\n",
    "        assert inp_img is not None\n",
    "        seg_img = overlay_seg_image(inp_img, seg_img)\n",
    "\n",
    "    if show_legends:\n",
    "        assert class_names is not None\n",
    "        legend_img = get_legends(class_names, colors=colors)\n",
    "\n",
    "        seg_img = concat_lenends(seg_img, legend_img)\n",
    "\n",
    "    return seg_img\n",
    "\n",
    "def get_colored_segmentation_image(seg_arr, n_classes, colors=class_colors):\n",
    "    output_height = seg_arr.shape[0]\n",
    "    output_width = seg_arr.shape[1]\n",
    "\n",
    "    seg_img = np.zeros((output_height, output_width, 3))\n",
    "\n",
    "    for c in range(n_classes):\n",
    "        seg_arr_c = seg_arr[:, :] == c\n",
    "        seg_img[:, :, 0] += ((seg_arr_c)*(colors[c][0])).astype('uint8')\n",
    "        seg_img[:, :, 1] += ((seg_arr_c)*(colors[c][1])).astype('uint8')\n",
    "        seg_img[:, :, 2] += ((seg_arr_c)*(colors[c][2])).astype('uint8')\n",
    "\n",
    "    return seg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f30607",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_img=False\n",
    "show_legends=False\n",
    "class_names=None\n",
    "prediction_width=None\n",
    "prediction_height=None\n",
    "\n",
    "seg_img = visualize_segmentation(pr, inp, n_classes=n_classes,\n",
    "                                 colors=class_colors, overlay_img=overlay_img,\n",
    "                                 show_legends=show_legends,\n",
    "                                 class_names=class_names,\n",
    "                                 prediction_width=prediction_width,\n",
    "                                 prediction_height=prediction_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3a3ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    cv2.imshow('im', seg_img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60084169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fda16d1ff28>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(pr_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b9c11b",
   "metadata": {},
   "source": [
    "### Use the below if you are loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b7a6960",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown layer: QuantizeLayer. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7e2870f6e905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#model = vgg_unet(n_classes=50 ,  input_height=320, input_width=640  )\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#model7_p=load_model('./striped_divam_ss_pruned_ep_model_20_r_segnet.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel_qq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./divam_ss_q_model_.15.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#model_base=load_model('./dg_base_ep1.h5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'done'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/divamgupta_tf2/lib/python3.6/site-packages/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    199\u001b[0m             (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m    200\u001b[0m           return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n\u001b[0;32m--> 201\u001b[0;31m                                                   compile)\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/divamgupta_tf2/lib/python3.6/site-packages/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[0;32m--> 181\u001b[0;31m                                                custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/divamgupta_tf2/lib/python3.6/site-packages/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     50\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/divamgupta_tf2/lib/python3.6/site-packages/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/virtualenv/divamgupta_tf2/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    676\u001b[0m             custom_objects=dict(\n\u001b[1;32m    677\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m                 list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    679\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/divamgupta_tf2/lib/python3.6/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSharedObjectLoadingScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m       input_tensors, output_tensors, created_layers = reconstruct_from_config(\n\u001b[0;32m--> 663\u001b[0;31m           config, custom_objects)\n\u001b[0m\u001b[1;32m    664\u001b[0m       model = cls(inputs=input_tensors, outputs=output_tensors,\n\u001b[1;32m    665\u001b[0m                   name=config.get('name'))\n",
      "\u001b[0;32m~/virtualenv/divamgupta_tf2/lib/python3.6/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   1271\u001b[0m   \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1273\u001b[0;31m     \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1274\u001b[0m   \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1275\u001b[0m   \u001b[0;31m# Nodes that cannot yet be processed (if the inbound node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/divamgupta_tf2/lib/python3.6/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1253\u001b[0m       \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdeserialize_layer\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m       \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeserialize_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m       \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/divamgupta_tf2/lib/python3.6/site-packages/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    210\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLOCAL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL_OBJECTS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m~/virtualenv/divamgupta_tf2/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     (cls, cls_config) = class_and_config_for_serialized_keras_object(\n\u001b[0;32m--> 660\u001b[0;31m         config, module_objects, custom_objects, printable_module_name)\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;31m# If this object has already been loaded (i.e. it's shared between multiple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenv/divamgupta_tf2/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mclass_and_config_for_serialized_keras_object\u001b[0;34m(config, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;34m'https://www.tensorflow.org/guide/keras/save_and_serialize'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;34m'#registering_the_custom_object for details.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         .format(printable_module_name, class_name))\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m   \u001b[0mcls_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown layer: QuantizeLayer. Please ensure this object is passed to the `custom_objects` argument. See https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object for details."
     ]
    }
   ],
   "source": [
    "from keras_segmentation.models.unet import vgg_unet\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#model = vgg_unet(n_classes=50 ,  input_height=320, input_width=640  )\n",
    "#model7_p=load_model('./striped_divam_ss_pruned_ep_model_20_r_segnet.h5')\n",
    "model_qq=load_model('./divam_ss_q_model_.15.h5')\n",
    "#model_base=load_model('./dg_base_ep1.h5')\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24dd6582",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_scope = tfmot.quantization.keras.quantize_scope\n",
    "with quantize_scope():\n",
    "    model_qq=load_model('./divam_ss_q_model_.15.h5')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997cdd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e57be9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "inp = cv2.imread(\"dataset1/images_prepped_test/0016E5_07965.png\",1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6b55d",
   "metadata": {},
   "source": [
    "### Pruning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a89b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot \n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule as pruning_sched\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97ce848",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 367\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.80,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "#'''\n",
    "\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model_base, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3875d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250de17",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_checkpoints_path = 'divam_ss_pruned_weights_r_segnet'\n",
    "p_checkpoint = ModelCheckpoint(filepath=p_checkpoints_path + \"{epoch:02d}.h5\",save_weights_only=True,save_best_only=True,\n",
    "                               monitor='loss',\n",
    "                              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23528d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = './pruning_logs'\n",
    "p_callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    # Log sparsity and other metrics in Tensorboard.\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir),p_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a439890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "# Better Model callbacks\n",
    "log_dir = '.\\pruning_logs'\n",
    "p_callbacks_n = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tensorflow.keras.callbacks.TensorBoard(log_dir=log_dir, profile_batch = 100000000, histogram_freq=0, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None, embeddings_data=None, update_freq='epoch'),\n",
    "  tfmot.sparsity.keras.PruningSummaries(\n",
    "    log_dir, update_freq='epoch'\n",
    "  ), p_checkpoint\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133d2697",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_k = 'categorical_crossentropy'\n",
    "\n",
    "model_for_pruning.compile(loss=loss_k,\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa0041",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_epoch=0\n",
    "model_for_pruning.fit(train_gen, steps_per_epoch=steps_per_epoch,\n",
    "                  epochs=epochs, callbacks=p_callbacks_n, initial_epoch=initial_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d889a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = model_for_pruning.predict(np.array([x]))[0]\n",
    "pr_p1 = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e194508",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_pruning.save('divam_ss_pruned_ep_model_20_r_segnet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec8c0bf",
   "metadata": {},
   "source": [
    "### Strip pruning to remove the pruning layer names to the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989154f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "model_for_export.save('striped_divam_ss_pruned_ep_model_20_r_segnet.h5', include_optimizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee72f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_pruning.save_weights('divam_ss_pruned_ep_weights_20_new.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7d9359",
   "metadata": {},
   "source": [
    "### End to end inference from a loaded model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d76e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras_segmentation.models.unet import vgg_unet\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "#model9 = vgg_unet(n_classes=50 ,  input_height=320, input_width=640  )\n",
    "model7=load_model('./striped_divam_ss_pruned_ep_model_20_r_segnet.h5')\n",
    "#model9=load_model('./dg_base_ep1.h5')\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "inp = cv2.imread(\"dataset1/images_prepped_test/0016E5_07965.png\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78453ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 50\n",
    "input_height = 320\n",
    "input_width = 640\n",
    "output_height = 160\n",
    "output_width = 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef22174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_array(image_input,\n",
    "                    width, height,\n",
    "                    imgNorm=\"sub_mean\", ordering='channels_first', read_image_type=1):\n",
    "    \"\"\" Load image array from input \"\"\"\n",
    "\n",
    "    if type(image_input) is np.ndarray:\n",
    "        # It is already an array, use it as it is\n",
    "        img = image_input\n",
    "    elif isinstance(image_input, six.string_types):\n",
    "        if not os.path.isfile(image_input):\n",
    "            raise DataLoaderError(\"get_image_array: path {0} doesn't exist\"\n",
    "                                  .format(image_input))\n",
    "        img = cv2.imread(image_input, read_image_type)\n",
    "    else:\n",
    "        raise DataLoaderError(\"get_image_array: Can't process input type {0}\"\n",
    "                              .format(str(type(image_input))))\n",
    "\n",
    "    if imgNorm == \"sub_and_divide\":\n",
    "        img = np.float32(cv2.resize(img, (width, height))) / 127.5 - 1\n",
    "    elif imgNorm == \"sub_mean\":\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img = np.atleast_3d(img)\n",
    "\n",
    "        means = [103.939, 116.779, 123.68]\n",
    "\n",
    "        for i in range(min(img.shape[2], len(means))):\n",
    "            img[:, :, i] -= means[i]\n",
    "\n",
    "        img = img[:, :, ::-1]\n",
    "    elif imgNorm == \"divide\":\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img = img/255.0\n",
    "\n",
    "    if ordering == 'channels_first':\n",
    "        img = np.rollaxis(img, 2, 0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c49df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "IMAGE_ORDERING = \"channels_last\"\n",
    "x = get_image_array(inp, input_width, input_height,\n",
    "                    ordering=IMAGE_ORDERING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ec052f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = model_qq.predict(np.array([x]))[0]\n",
    "pr_p = pr.reshape((output_height,  output_width, n_classes)).argmax(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0f3173",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2552a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class_colors = [(random.randint(0, 255), random.randint(\n",
    "    0, 255), random.randint(0, 255)) for _ in range(5000)]\n",
    "\n",
    "def visualize_segmentation(seg_arr, inp_img=None, n_classes=None,\n",
    "                           colors=class_colors, class_names=None,\n",
    "                           overlay_img=False, show_legends=False,\n",
    "                           prediction_width=None, prediction_height=None):\n",
    "\n",
    "    if n_classes is None:\n",
    "        n_classes = np.max(seg_arr)\n",
    "\n",
    "    seg_img = get_colored_segmentation_image(seg_arr, n_classes, colors=colors)\n",
    "\n",
    "    if inp_img is not None:\n",
    "        original_h = inp_img.shape[0]\n",
    "        original_w = inp_img.shape[1]\n",
    "        seg_img = cv2.resize(seg_img, (original_w, original_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    if (prediction_height is not None) and (prediction_width is not None):\n",
    "        seg_img = cv2.resize(seg_img, (prediction_width, prediction_height), interpolation=cv2.INTER_NEAREST)\n",
    "        if inp_img is not None:\n",
    "            inp_img = cv2.resize(inp_img,\n",
    "                                 (prediction_width, prediction_height))\n",
    "\n",
    "    if overlay_img:\n",
    "        assert inp_img is not None\n",
    "        seg_img = overlay_seg_image(inp_img, seg_img)\n",
    "\n",
    "    if show_legends:\n",
    "        assert class_names is not None\n",
    "        legend_img = get_legends(class_names, colors=colors)\n",
    "\n",
    "        seg_img = concat_lenends(seg_img, legend_img)\n",
    "\n",
    "    return seg_img\n",
    "\n",
    "def get_colored_segmentation_image(seg_arr, n_classes, colors=class_colors):\n",
    "    output_height = seg_arr.shape[0]\n",
    "    output_width = seg_arr.shape[1]\n",
    "\n",
    "    seg_img = np.zeros((output_height, output_width, 3))\n",
    "\n",
    "    for c in range(n_classes):\n",
    "        seg_arr_c = seg_arr[:, :] == c\n",
    "        seg_img[:, :, 0] += ((seg_arr_c)*(colors[c][0])).astype('uint8')\n",
    "        seg_img[:, :, 1] += ((seg_arr_c)*(colors[c][1])).astype('uint8')\n",
    "        seg_img[:, :, 2] += ((seg_arr_c)*(colors[c][2])).astype('uint8')\n",
    "\n",
    "    return seg_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fa29d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay_img=False\n",
    "show_legends=False\n",
    "class_names=None\n",
    "prediction_width=None\n",
    "prediction_height=None\n",
    "\n",
    "seg_img = visualize_segmentation(pr, inp, n_classes=n_classes,\n",
    "                                 colors=class_colors, overlay_img=overlay_img,\n",
    "                                 show_legends=show_legends,\n",
    "                                 class_names=class_names,\n",
    "                                 prediction_width=prediction_width,\n",
    "                                 prediction_height=prediction_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6e87a52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fda0a0a7cf8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(pr_p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
